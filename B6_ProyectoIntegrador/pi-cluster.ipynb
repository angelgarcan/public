{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple outputs per cell in Jupyter \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "// Evitar autoscroll.\n",
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "// Evitar autoscroll.\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# from toolbox import *\n",
    "import toolbox as tb\n",
    "from skeleton import *\n",
    "import pandas as pd\n",
    "from gensim.models import FastText\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import tqdm\n",
    "from microtc.utils import tweet_iterator\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import gc\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokens():\n",
    "    tokenized_pointer=None\n",
    "    \n",
    "    def tokenize(self,json_file,npy_file=None,replace=False,showProgressEach=1000):\n",
    "        self.npy_file=str(os.path.splitext(json_file)[0]+\".npy\") if not npy_file else npy_file\n",
    "\n",
    "        if not replace and os.path.isfile(self.npy_file):\n",
    "            print(f\"** Replace is off. {os.path.abspath(self.npy_file)} already exists, then load.\")\n",
    "        else:\n",
    "            tokenized_docs=[]\n",
    "            self.N=0\n",
    "            print(f\"** Processing {json_file} ...\")\n",
    "            tx = datetime.datetime.now()\n",
    "            for idx, tw in enumerate(tweet_iterator(json_file)):\n",
    "                tb.show_progress(showProgressEach, tx, idx)\n",
    "                twTokens = tb.process_line(tw['text']) # Tokenizando tweet.\n",
    "                tokenized_docs.append(twTokens)\n",
    "            self.N=idx+1\n",
    "        \n",
    "            maxLen=len(max(tokenized_docs))\n",
    "            for i, doc in enumerate(tokenized_docs):\n",
    "                tokenized_docs[i]=[doc[x] if x<len(doc) else '' for x in range(maxLen)]\n",
    "            \n",
    "            np.save(self.npy_file,tokenized_docs)\n",
    "            del(tokenized_docs)\n",
    "            gc.collect()\n",
    "            print(f\"** Processed {self.N} lines. Saved to {os.path.abspath(self.npy_file)}.\")\n",
    "        \n",
    "        self.pointer=np.load(self.npy_file, mmap_mode='r')\n",
    "        return self\n",
    "    \n",
    "    def get(self,n):\n",
    "        return [x for x in self.pointer[n,:] if x != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -f data/*.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Processing data/geo-mx-2004.json ...\n",
      "2020-05-12 15:15:56.669592 :: 0.00031 - Processing item #0 \n",
      "2020-05-12 15:16:05.114605 :: 8.445323 - Processing item #10000 \n",
      "2020-05-12 15:16:13.785040 :: 17.115758 - Processing item #20000 \n",
      "2020-05-12 15:16:21.337940 :: 24.668658 - Processing item #30000 \n",
      "2020-05-12 15:16:28.860174 :: 32.190892 - Processing item #40000 \n",
      "2020-05-12 15:16:36.055687 :: 39.386405 - Processing item #50000 \n",
      "2020-05-12 15:16:43.206188 :: 46.536906 - Processing item #60000 \n",
      "2020-05-12 15:16:50.993421 :: 54.324139 - Processing item #70000 \n",
      "2020-05-12 15:16:58.527787 :: 61.858505 - Processing item #80000 \n",
      "2020-05-12 15:17:05.914452 :: 69.24517 - Processing item #90000 \n",
      "2020-05-12 15:17:13.477884 :: 76.808602 - Processing item #100000 \n",
      "2020-05-12 15:17:21.574797 :: 84.905515 - Processing item #110000 \n",
      "2020-05-12 15:17:29.144386 :: 92.475104 - Processing item #120000 \n",
      "2020-05-12 15:17:38.463473 :: 101.794191 - Processing item #130000 \n",
      "2020-05-12 15:17:46.268061 :: 109.598779 - Processing item #140000 \n",
      "2020-05-12 15:17:53.538484 :: 116.869202 - Processing item #150000 \n",
      "2020-05-12 15:18:01.237669 :: 124.568387 - Processing item #160000 \n",
      "2020-05-12 15:18:08.733685 :: 132.064403 - Processing item #170000 \n",
      "2020-05-12 15:18:16.894797 :: 140.225515 - Processing item #180000 \n",
      "2020-05-12 15:18:24.623128 :: 147.953846 - Processing item #190000 \n",
      "** Processed 200000 lines. Saved to /home/jovyan/public/B6_ProyectoIntegrador/data/geo-mx-2004.npy.\n"
     ]
    }
   ],
   "source": [
    "tokens=Tokens().tokenize(\"data/geo-mx-2004.json\",replace=True,showProgressEach=10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
