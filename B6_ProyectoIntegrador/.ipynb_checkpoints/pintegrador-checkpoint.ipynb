{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple outputs per cell in Jupyter \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "// Evitar autoscroll.\n",
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "// Evitar autoscroll.\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4), (3, 5), (2, 6)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(1, 3, 2), (4, 5, 6)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[1, 3, 2]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[4, 5, 6]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = [1,2,3]\n",
    "# b = [4,5,6]\n",
    "# zipped_list = zip(a,b)\n",
    "zipped_list=[(1, 4), (3, 5), (2, 6)]\n",
    "zipped_list\n",
    "unzipped_list=list(zip(*zipped_list))\n",
    "unzipped_list\n",
    "list(unzipped_list[0])\n",
    "list(unzipped_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4), (2, 6), (3, 5)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(1, 2, 3), (4, 6, 5)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 6, 5]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=[(1, 4), (3, 5), (2, 6)]\n",
    "\n",
    "p.sort()\n",
    "p\n",
    "\n",
    "p=list(zip(*p))\n",
    "p\n",
    "\n",
    "p=[list(p[0]),list(p[1])]\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# from toolbox import *\n",
    "import toolbox as tb\n",
    "from skeleton import *\n",
    "import pandas as pd\n",
    "from gensim.models import FastText\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import tqdm\n",
    "from microtc.utils import tweet_iterator\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokens():\n",
    "    tokenized_pointer=None\n",
    "    \n",
    "    def tokenize(self,json_file,npy_file=None,replace=False):\n",
    "        self.npy_file=str(os.path.splitext(json_file)[0]+\".npy\") if not npy_file else npy_file\n",
    "\n",
    "        if not replace and os.path.isfile(self.npy_file):\n",
    "            print(f\"** Replace is off. {os.path.abspath(self.npy_file)} already exists, then load.\")\n",
    "        else:\n",
    "            tokenized_docs=[]\n",
    "            self.N=0\n",
    "            print(f\"** Processing {json_file} ...\")\n",
    "            tx = datetime.datetime.now()\n",
    "            for idx, tw in enumerate(tweet_iterator(json_file)):\n",
    "                tb.show_progress(1000, tx, idx)\n",
    "                twTokens = tb.process_line(tw['text']) # Limpiando text.\n",
    "#                 print(type(twTokens))\n",
    "                tokenized_docs.append(twTokens)\n",
    "            \n",
    "#             print(\"max:\",len(max(tokenized_docs)))\n",
    "    \n",
    "            self.N=idx+1\n",
    "#             print(type(tokenized_docs),len(tokenized_docs))\n",
    "#             print(tokenized_docs)\n",
    "#             tokenized_docs\n",
    "            maxLen=len(max(tokenized_docs))\n",
    "            for i, doc in enumerate(tokenized_docs):\n",
    "#                 print(\"Before:\",tokenized_docs[i])\n",
    "#                 print(doc, ['']*(maxLen - len(doc)))\n",
    "#                 tokenized_docs[i] = doc + ['']*(maxLen - len(doc))\n",
    "                tokenized_docs[i]=[doc[x] if x<len(doc) else '' for x in range(maxLen)]\n",
    "#                 print(\"After:\",tokenized_docs[i])\n",
    "            \n",
    "            np.save(self.npy_file,tokenized_docs)\n",
    "            del(tokenized_docs)\n",
    "            gc.collect()\n",
    "            print(f\"** Processed {self.N} lines. Saved to {os.path.abspath(self.npy_file)}.\")\n",
    "        \n",
    "        self.pointer=np.load(self.npy_file, mmap_mode='r')\n",
    "        return self\n",
    "    \n",
    "    def get(n):\n",
    "        return self.pointer[n,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Processing data/geo-mx-2004_min.json ...\n",
      "2020-05-12 03:17:57.938913 :: 0.000152 - Processing item #0 \n",
      "** Processed 10 lines. Saved to /home/jovyan/public/B6_ProyectoIntegrador/data/geo-mx-2004_min.npy.\n"
     ]
    }
   ],
   "source": [
    "tokens=Tokens().tokenize(\"data/geo-mx-2004_min.json\",replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap(['nochecit', '', '', '', '', '', '', '', '', ''], dtype='<U9')"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.pointer[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Index():\n",
    "#     vocab = None\n",
    "    N = 0\n",
    "    DF = Counter({})\n",
    "    TF = []\n",
    "    \n",
    "#     DF_vec = None\n",
    "#     IDF_vec = None\n",
    "\n",
    "    def computePostingLists(self, filename, showProgressEach=None):\n",
    "        print(\"** Processing \" + filename + \"...\")\n",
    "#         tx = datetime.datetime.now()\n",
    "        for idx, tw in tqdm(enumerate(tweet_iterator(filename))):\n",
    "#             tb.show_progress(showProgressEach,tx,idx)\n",
    "            twTxtLst = tb.process_line(tw['text']) # Limpiando text.\n",
    "            \n",
    "            # Sumando frecuencias individiales.\n",
    "            twCnt = Counter(twTxtLst)\n",
    "            \n",
    "            TF.append(twCnt)\n",
    "            \n",
    "            # Sumando frecuencias por documento (DF).\n",
    "            self.DF.update(list(twCnt.keys()))\n",
    "\n",
    "            # Contabilizando documentos.\n",
    "            self.N += 1\n",
    "            \n",
    "#         words = self.DF.keys()\n",
    "#         self.vocab = dict(zip(words, range(len(words))))\n",
    "#         self.DF_vec = cnt2vec(self.DF, self.vocab)\n",
    "#         self.IDF_vec = np.log2(self.N / (self.DF_vec + 1))\n",
    "        \n",
    "#         # Calculando TF-IDF y asignando a usuarios.\n",
    "#         for userId in self.users:\n",
    "#             TF_cnt = self.users[userId]\n",
    "#             self.users[userId] = cnt2vec(TF_cnt, self.vocab) * self.IDF_vec\n",
    "        postlists=defaultdict(list)\n",
    "\n",
    "    def getX(self):\n",
    "        return np.array([self.users[key] for key in self.users])\n",
    "    \n",
    "    def cluster(self, n_clusters=9):\n",
    "        self.cluster = KMeans(n_clusters=n_clusters, n_jobs=4).fit(self.getX())\n",
    "        return self.cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj=np.arange(100*50000).reshape((50000,100))\n",
    "obj=[['nochecit',''], \n",
    "     ['teo', 'pai'], \n",
    "     ['jajajaj', 'sab'], \n",
    "     ['obvi', 'hoy']]\n",
    "# obj=[Counter(['nochecit','nochecit']), \n",
    "#      Counter(['teo', 'pai']), \n",
    "#      Counter(['jajajaj', 'sab']), \n",
    "#      Counter(['obvi', 'hoy'])]\n",
    "# obj=[[1], \n",
    "#      [3, 4], \n",
    "#      [5, 6], \n",
    "#      [7, 8]]\n",
    "# np.save(\"obj.npy\",obj,allow_pickle=True)\n",
    "np.save(\"obj.npy\",obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a': 2, 'b': 1, None: 1})"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(['a','b','a',None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap(['nochecit', ''], dtype='<U8')"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.load(\"obj.npy\", mmap_mode='r')\n",
    "X[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load() got an unexpected keyword argument 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-22c40e5f427c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"obj.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# X = np.load(\"obj.npy\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# for i in range(20):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: load() got an unexpected keyword argument 'shape'"
     ]
    }
   ],
   "source": [
    "X = np.load(\"obj.npy\", mmap_mode='r',shape=(4,2))\n",
    "X.shape\n",
    "X[1,:]\n",
    "# X = np.load(\"obj.npy\")\n",
    "# for i in range(20):\n",
    "#     print(X[i, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__name__ 57\n",
      "__doc__ 113\n",
      "__package__ 16\n",
      "__loader__ 16\n",
      "__spec__ 16\n",
      "__builtin__ 88\n",
      "__builtins__ 88\n",
      "_ih 1456\n",
      "_oh 2288\n",
      "_dh 80\n",
      "In 1456\n",
      "Out 2288\n",
      "get_ipython 72\n",
      "exit 64\n",
      "quit 64\n",
      "_ 128\n",
      "__ 144\n",
      "___ 264\n",
      "_i 91\n",
      "_ii 82\n",
      "_iii 76\n",
      "_i1 195\n",
      "InteractiveShell 1064\n",
      "_i2 167\n",
      "_i3 225\n",
      "np 88\n",
      "tb 88\n",
      "skmeans 1064\n",
      "transforms 88\n",
      "plt 88\n",
      "cm 88\n",
      "nltk 88\n",
      "itertools 88\n",
      "string 88\n",
      "unicodedata 88\n",
      "re 88\n",
      "word_tokenize 144\n",
      "PCA 1064\n",
      "pd 88\n",
      "faiss 88\n",
      "axes3d 88\n",
      "punctuation_table 1192\n",
      "stop_words 2904\n",
      "euclidiana 144\n",
      "coseno 144\n",
      "plotClusters 144\n",
      "plotPCA 144\n",
      "preprocess 144\n",
      "tokenize_sentences 144\n",
      "cocurrency_matrix 144\n",
      "plotDecisionBoundary 144\n",
      "NearestCentroid 1064\n",
      "kNN 1064\n",
      "Clustering 1064\n",
      "FastText 1064\n",
      "_i4 58\n",
      "_i5 154\n",
      "X 144\n",
      "_i6 117\n",
      "obj 104\n",
      "_i7 154\n",
      "_i8 154\n",
      "_i9 162\n",
      "_9 72\n",
      "_i10 210\n",
      "sys 88\n",
      "local_vars 712\n",
      "tot 28\n",
      "var 52\n",
      "mem 28\n",
      "_i11 1045\n",
      "_i12 1044\n",
      "Tokens 1064\n",
      "_i13 1076\n",
      "_i14 97\n",
      "_i15 235\n",
      "os 88\n",
      "_i16 1076\n",
      "_i17 97\n",
      "_i18 247\n",
      "tqdm 88\n",
      "_i19 1076\n",
      "_i20 97\n",
      "_i21 288\n",
      "tweet_iterator 144\n",
      "_i22 1076\n",
      "_i23 97\n",
      "_i24 1076\n",
      "_i25 97\n",
      "_i26 1166\n",
      "_i27 1159\n",
      "_i28 97\n",
      "_i29 304\n",
      "_i30 304\n",
      "datetime 88\n",
      "_i31 1159\n",
      "_i32 97\n",
      "_i33 102\n",
      "_i34 1183\n",
      "_i35 102\n",
      "_i36 1229\n",
      "_i37 1229\n",
      "_i38 102\n",
      "_i39 1236\n",
      "_i40 102\n",
      "_i41 1284\n",
      "_i42 102\n",
      "_i43 1332\n",
      "_i44 102\n",
      "_i45 1335\n",
      "_i46 102\n",
      "_i47 1423\n",
      "_i48 102\n",
      "_i49 1433\n",
      "_i50 102\n",
      "_i51 1438\n",
      "_i52 102\n",
      "_i53 1516\n",
      "_i54 102\n",
      "_i55 115\n",
      "_i56 1245\n",
      "_i57 1247\n",
      "_i58 115\n",
      "_i59 1281\n",
      "_i60 115\n",
      "_i61 66\n",
      "_61 136\n",
      "_i62 66\n",
      "_62 112\n",
      "_i63 66\n",
      "_63 112\n",
      "_i64 66\n",
      "_64 112\n",
      "_i65 66\n",
      "_65 112\n",
      "_i66 66\n",
      "_66 112\n",
      "_i67 66\n",
      "_67 112\n",
      "_i68 66\n",
      "_68 112\n",
      "_i69 66\n",
      "_69 112\n",
      "_i70 66\n",
      "_70 112\n",
      "_i71 66\n",
      "_71 112\n",
      "_i72 66\n",
      "_72 112\n",
      "_i73 66\n",
      "_73 112\n",
      "_i74 66\n",
      "_74 112\n",
      "_i75 66\n",
      "_75 112\n",
      "_i76 66\n",
      "_76 112\n",
      "_i77 66\n",
      "_77 112\n",
      "_i78 66\n",
      "_78 112\n",
      "_i79 66\n",
      "_79 112\n",
      "_i80 66\n",
      "_80 112\n",
      "_i81 66\n",
      "_81 112\n",
      "_i82 66\n",
      "_82 112\n",
      "_i83 66\n",
      "_83 112\n",
      "_i84 66\n",
      "_84 112\n",
      "_i85 66\n",
      "_85 112\n",
      "_i86 66\n",
      "_86 112\n",
      "_i87 66\n",
      "_87 112\n",
      "_i88 66\n",
      "_88 112\n",
      "_i89 66\n",
      "_89 112\n",
      "_i90 66\n",
      "_90 112\n",
      "_i91 66\n",
      "_91 112\n",
      "_i92 66\n",
      "_92 112\n",
      "_i93 66\n",
      "_93 112\n",
      "_i94 66\n",
      "_94 112\n",
      "_i95 66\n",
      "_95 112\n",
      "_i96 66\n",
      "_96 112\n",
      "_i97 66\n",
      "_97 112\n",
      "_i98 66\n",
      "_98 112\n",
      "_i99 66\n",
      "_99 112\n",
      "_i100 66\n",
      "_100 112\n",
      "_i101 66\n",
      "_101 112\n",
      "_i102 66\n",
      "_102 112\n",
      "_i103 66\n",
      "_103 112\n",
      "_i104 66\n",
      "_104 112\n",
      "_i105 117\n",
      "_i106 162\n",
      "_106 72\n",
      "_i107 363\n",
      "_i108 162\n",
      "_i109 218\n",
      "_i110 162\n",
      "_110 72\n",
      "_i111 169\n",
      "_111 128\n",
      "_i112 207\n",
      "_i113 169\n",
      "_i114 219\n",
      "_i115 207\n",
      "_i116 181\n",
      "_i117 78\n",
      "_117 128\n",
      "_i118 94\n",
      "_i119 218\n",
      "_i120 82\n",
      "_120 144\n",
      "_i121 78\n",
      "_121 128\n",
      "_i122 207\n",
      "_i123 218\n",
      "_i124 82\n",
      "_124 144\n",
      "_i125 82\n",
      "_125 144\n",
      "_i126 91\n",
      "_126 128\n",
      "_i127 218\n",
      "_i128 91\n",
      "_128 128\n",
      "_i129 94\n",
      "_i130 91\n",
      "_i131 282\n",
      "_i132 82\n",
      "_132 144\n",
      "_i133 280\n",
      "_i134 82\n",
      "_i135 85\n",
      "_i136 280\n",
      "_i137 82\n",
      "_137 144\n",
      "_i138 272\n",
      "_i139 82\n",
      "_139 144\n",
      "_i140 269\n",
      "_i141 82\n",
      "_i142 100\n",
      "_i143 287\n",
      "_i144 100\n",
      "_i145 313\n",
      "_i146 82\n",
      "_i147 447\n",
      "_i148 336\n",
      "Counter 1064\n",
      "_i149 447\n",
      "_i150 82\n",
      "_i151 458\n",
      "_i152 82\n",
      "_i153 74\n",
      "_153 264\n",
      "_i154 76\n",
      "_154 264\n",
      "_i155 458\n",
      "_i156 82\n",
      "_i157 462\n",
      "_i158 76\n",
      "_158 264\n",
      "_i159 82\n",
      "_i160 461\n",
      "_i161 76\n",
      "_161 264\n",
      "_i162 82\n",
      "_162 144\n",
      "_i163 462\n",
      "_i164 462\n",
      "_i165 76\n",
      "_165 264\n",
      "_i166 82\n",
      "_i167 461\n",
      "_i168 460\n",
      "_i169 76\n",
      "_169 264\n",
      "_i170 82\n",
      "_170 144\n",
      "_i171 91\n",
      "_171 128\n",
      "_i172 210\n",
      "Total = 85746\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "local_vars = list(locals().items())\n",
    "tot=0\n",
    "for var, obj in local_vars:\n",
    "    mem=sys.getsizeof(obj)\n",
    "    tot+=mem\n",
    "    print(var, mem)\n",
    "print(\"Total =\",tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
