{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Multiple outputs per cell in Jupyter \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%load_ext jupyternotify\n",
    "%autonotify -a 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "// Evitar autoscroll.\n",
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "// Evitar autoscroll.\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from integrado import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Processing data/geo-mx-2004_min.json ...\n",
      "2020-05-12 19:59:21.160513 :: 0.000166 - Processing item #0 \n",
      "** Processed 1000 lines. Saved to /home/jovyan/public/B6_ProyectoIntegrador/data/geo-mx-2004_min.npy.\n"
     ]
    }
   ],
   "source": [
    "tokens=Tokens().tokenize(\"data/geo-mx-2004_min.json\",replace=True,showProgressEach=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Counting TF & DF ...\n",
      "2020-05-12 19:59:22.176658 :: 0.002929 - Processing item #0 \n",
      "** Calculating TF-IDF...\n",
      "2020-05-12 19:59:22.245640 :: 0.071911 - Processing item #0 \n",
      "** Sorting posting lists...\n",
      "2020-05-12 19:59:22.398810 :: 0.225081 - Processing item #0 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2435"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_=Index().computePostingLists(tokens,showProgressEach=10000)\n",
    "len(index_.postlists.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 [12, 39, 42, 104, 143]\n",
      "33 [['escucha', 'enlazados', 'informarse', 'pandemia', 'retransmision'], ['alturas', 'cuarentena', 'cuestiono', 'si', 'amigos'], ['si', 'sacrificar', 'colonia', 'culiacan', 'covid'], ['dice', 'vayamos', 'acabe', 'covid', 'da'], ['abril', 'mes', 'clave', 'tema', 'covid']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['#Qu√©dateEnCasa \\n#FelizMi√©rcoles\\nEscucha #UnidosPorLasAudienciasCovid19 enlazados a \\n@RadioEducacion para informarse  de la pandemia; y la retransmisi√≥n de los conciertos de la Orquesta Sinf√≥nica Nacional en honor a Beethoven en la programaci√≥n del 1 de #abril de 2020üê¨ https://t.co/EBgx6FdsOY',\n",
       " 'A estas alturas de la cuarentena #COVID19mx me cuestiono si mis \"amigos\" son muy positivos o muy pendejos;\\nLo que comprob√© es que soy muy tolerante',\n",
       " 'Si tuvieras que sacrificar una colonia de Culiac√°n por el Covid-19 ¬øCual ser√≠a? y ¬øPor qu√© Barrancos?',\n",
       " '@majoxmendez Dice que vayamos cuando acabe lo del Covid, que √©l da la casa y las klosters',\n",
       " '01 de abril del 2020 \\nUn mes clave para el tema del COVID19\\nCu√≠dense mucho y dentro de sus posibilidades qu√©dense en casa por favor üôå']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds=index_.o(\"covid coronavirus pandemia cuarentena\",tokenize=True)\n",
    "print(len(ds),ds[:5])\n",
    "docs=tokens.getToks(ds)\n",
    "print(len(docs),docs[:5])\n",
    "[tw['text'] for tw in tokens.getTws(ds[:5])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings():\n",
    "    \n",
    "    def __init__(self,tokens):        \n",
    "        model = FastText(size=100, window=3, min_count=1, min_n=2, max_n=5)\n",
    "        model.build_vocab(sentences=tokens)\n",
    "        model.train(sentences=tokens,total_examples=len(tokens), epochs=10)\n",
    "        self.embeddings_=np.array(\n",
    "            [np.mean([model.wv[tok] for tok in tw],axis=0) \n",
    "                   for tw in tokens])\n",
    "        del(model)\n",
    "        gc.collect()\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tokens' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-a56f27441d0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0membs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-bd38a9161e34>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         self.embeddings=np.array(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/gensim/models/fasttext.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, sentences, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m    723\u001b[0m         retval = super(FastText, self).build_vocab(\n\u001b[1;32m    724\u001b[0m             \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_per\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_per\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m             keep_raw_vocab=keep_raw_vocab, trim_rule=trim_rule, **kwargs)\n\u001b[0m\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, sentences, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m         \"\"\"\n\u001b[1;32m    935\u001b[0m         total_words, corpus_count = self.vocabulary.scan_vocab(\n\u001b[0;32m--> 936\u001b[0;31m             sentences=sentences, corpus_file=corpus_file, progress_per=progress_per, trim_rule=trim_rule)\n\u001b[0m\u001b[1;32m    937\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mscan_vocab\u001b[0;34m(self, sentences, corpus_file, progress_per, workers, trim_rule)\u001b[0m\n\u001b[1;32m   1590\u001b[0m             \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLineSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1592\u001b[0;31m         \u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scan_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_per\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m         logger.info(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m_scan_vocab\u001b[0;34m(self, sentences, progress_per, trim_rule)\u001b[0m\n\u001b[1;32m   1559\u001b[0m         \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1560\u001b[0m         \u001b[0mchecked_string_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1561\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msentence_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1562\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchecked_string_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1563\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Tokens' object is not iterable"
     ]
    }
   ],
   "source": [
    "embs=Embeddings(tokens)\n",
    "print(type(embs), len(embs))\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skeleton import Clustering\n",
    "class Clustering2(Clustering):\n",
    "    \n",
    "    # se asigna el m√©todo de inicializaci√≥n de Kmeans (default=\"fft\")\n",
    "    def __init__(self, *args, k_init=\"fft\", **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.k_init_ = k_init\n",
    "        \n",
    "    # asigna los elementos en la colecci√≥n a su centroide m√°s cercano\n",
    "    # genera las etiquetas de los clusters\n",
    "    # almacena la distancia de cada elemento a su centroide m√°s cercano\n",
    "    def _assign_nearest_centroids(self):\n",
    "        self.labels_=[-1 for _ in self.data]\n",
    "        self.dists_=[-1 for _ in self.data]\n",
    "        for j in range(len(self.data)):\n",
    "            dists = [(self.distance_function(c, self.data[j]), i, self.data[j])\n",
    "                     for i, c in self.centroids_.items()]\n",
    "            dists.sort()\n",
    "            self.labels_[j]=dists[0][1]\n",
    "            self.dists_[j]=(dists[0][0],j)\n",
    "            \n",
    "    def KMeans(self):\n",
    "        self.centroids_ = {}\n",
    "        C = []\n",
    "        if self.k_init_ == 'fft':\n",
    "            self.FFTraversal()\n",
    "            for i, c in self.centroids_.items():\n",
    "                C.append(c)\n",
    "        elif self.k_init_ == 'random':\n",
    "            C = np.random.uniform(low=np.min(self.data, axis=0) * .4,\n",
    "                                  high=np.max(self.data, axis=0) * .4,\n",
    "                                  size=(self.n_clusters, self.data.shape[1]))\n",
    "#             self.labels_ = []\n",
    "#             for i in range(len(self.data)):\n",
    "#                 self.labels_.append(np.int64(np.random.choice(range(self.n_clusters))))\n",
    "#             for i in range(self.n_clusters):\n",
    "#                 cs = self.data[np.where(self.labels_ == np.int64(i))[0]]\n",
    "#                 if len(cs) > 0:\n",
    "#                     C.append(np.mean(cs, axis=0))\n",
    "        else:\n",
    "            raise Exception(f\"k_init={self.k_init_} is not defined\")\n",
    "            \n",
    "        C = np.array(C)\n",
    "        error = np.inf\n",
    "        while error != 0:\n",
    "            self.labels_ = []\n",
    "            C_old = deepcopy(C)\n",
    "            for i in range(len(self.data)):\n",
    "                distances = [(self.distance_function(c, self.data[i]), j, self.data[i])\n",
    "                    for j, c in enumerate(C)]\n",
    "                distances.sort()\n",
    "                cluster = distances[0][1]\n",
    "                self.labels_.append(cluster)\n",
    "            for i in range(self.n_clusters):\n",
    "                cs = self.data[np.where(self.labels_ == np.int64(i))[0]]\n",
    "                if len(cs) > 0:\n",
    "                    C[i] = np.mean(cs, axis=0)\n",
    "            error = np.sum(C - C_old)\n",
    "        self.centroids_ = {}\n",
    "        for i, c in enumerate(C):\n",
    "            self.centroids_[np.int32(i)] = c\n",
    "        self._inertia()\n",
    "        return self\n",
    "\n",
    "    def FFTraversal(self):\n",
    "        self.centroids_ = {}\n",
    "        c1_idx = np.random.choice(self.data.shape[0])\n",
    "        self.centroids_[np.int32(c1_idx)] = self.data[c1_idx, :]\n",
    "        while len(self.centroids_.keys()) < self.n_clusters:\n",
    "            self._assign_nearest_centroids()\n",
    "            self.dists_.sort()\n",
    "            cn_idx=self.dists_[-1][1]\n",
    "            self.centroids_[np.int32(cn_idx)] = self.data[cn_idx, :]\n",
    "        self._assign_nearest_centroids()\n",
    "#         self.dists_.sort()\n",
    "        self._inertia()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total = 21002\n",
      "[(5688, 'ds'), (5504, 'docs'), (1064, 'Tokens'), (1064, 'InteractiveShell'), (1064, 'Index'), (1064, 'FastText'), (1064, 'Counter'), (400, 'defaultdict'), (278, '_i7'), (248, '_oh'), (248, 'Out'), (195, '_i1'), (172, '_i6'), (172, '_i'), (167, '_i2'), (144, 'tweet_iterator'), (138, '_iii'), (138, '_i4'), (136, '_ih'), (136, 'In'), (133, '_ii'), (133, '_i5'), (113, '__doc__'), (88, 'tb'), (88, 'sys'), (88, 'pd'), (88, 'os'), (88, 'np'), (88, 'gc'), (88, 'datetime'), (88, '__builtins__'), (88, '__builtin__'), (80, '_dh'), (72, 'get_ipython'), (72, '_i3'), (64, 'tokens'), (64, 'quit'), (64, 'index_'), (64, 'exit'), (57, '__name__'), (53, '___'), (53, '__'), (28, '_7'), (28, '_'), (16, '__spec__'), (16, '__package__'), (16, '__loader__')]\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "import sys\n",
    "local_vars = list(locals().items())\n",
    "tot=0\n",
    "vars_=[]\n",
    "for var, obj in local_vars:\n",
    "    mem=sys.getsizeof(obj)\n",
    "    tot+=mem\n",
    "    vars_.append((mem,var))\n",
    "print(\"Total =\",tot)\n",
    "vars_.sort(reverse=True)\n",
    "print(vars_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
