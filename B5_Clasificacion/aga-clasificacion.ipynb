{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 5.1. Clasificaci칩n de textos. Identificaci칩n de humor.\n",
    "\n",
    "|||\n",
    "|-|-|\n",
    "|**Alumno**|츼ngel Garc칤a Alc치ntara<br><angelgarcan@gmail.com>|\n",
    "|**Materia**|Recuperaci칩n de informaci칩n<br>en Bases de datos no estructuradas<br>Cuarto Semestre|\n",
    "|**Fecha**|20 de abril de 2020|\n",
    "\n",
    "<br>\n",
    "Implementar las diferentes estrategias de generaci칩n de centroides para los clasificadores Nearest Centroid as칤 como las formas de pesado para el clasificador de vecinos cercanos. \n",
    "\n",
    "- Una vez implementados aplicar todas las versiones de los mismos al dataset HAHA 2019. Se deben reportar el desempe침o. En la siguiente tabla se incluyen las m칠tricas de desempe침o a reportar para el clasificador incluido con FastText, as칤 como para el Nerarest Centroid Average y $k$NN con pesado uniforme proporcionado en las palantillas.\n",
    "\n",
    "------\n",
    "\n",
    "*Tabla de desempe침o para distintos clasificadores utilizando los vectores FastText\n",
    "pre-entrenados para el idioma espa침ol*\n",
    "\n",
    "------\n",
    "|Clasificador|Accuracy|Macro F1|Macro Recall|F1 is_humor=1|\n",
    "|:----------:|:------:|:------:|:----------:|:-----------:|\n",
    "|FastText| 0.80905 | 0.79327|0.78690|0.73614|\n",
    "|Nearest Centroid (Average)|0.76475 |0.76006|0.77290|0.72650|\n",
    "|$k$NN (Pesado Uniforme)|0.79252|0.77397|0.76704|0.70922|\n",
    "|Nearest Centroid (Rocchio)|\n",
    "|Nearest Centroid (Suma)|\n",
    "|Nearest Centroid (Suma normalizada)| \n",
    "|$k$NN (distancia m칤nima media)|  \n",
    "|$k$NN (distancia pesada)| \n",
    "\n",
    "------\n",
    "<br />\n",
    "\n",
    "En su reporte deber치 completar la tabla con los resultados para cada una de las variaciones de los alagoritmos propuestos. \n",
    "\n",
    "- Generar los una representaci칩n con pesado tfidf para el dataset HAHA 2019, posteriormente aplicar los clasificadores implementados a la representaci칩n generada. Incluir los resultados en forma de tabla. Justificar los resultados obtenidos en funci칩n de como son con los obtenidos sobre los vectores pre-entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducci칩n\n",
    "\n",
    "### Clasificaci칩n\n",
    "La tarea de clasificaci칩n es un tarea de aprendizaje supervisado, \n",
    "la cual consiste en predecir una variable categ칩rica, esto a partir \n",
    "de un conjunto de elementos ya categorizados. Por ejemplo:\n",
    "\n",
    "- Definir si un correo electr칩nico es o no spam\n",
    "- Si un paciente padece o no cierta enfermedad\n",
    "- An치lisis de polaridad en mensajes de twitter\n",
    "- Detecci칩n de humor, determinar si un texto es o no un chiste \n",
    "- Si un objeto aparece o no en una imagen \n",
    "\n",
    "Todos los ejemplos mencionados pueden plantearse como: generar \n",
    "un mapeo o etiquetado de un conjunto de datos $X$ (tweets, \n",
    "documentos, im치genes, registros medicos) con respecto a un conjunto \n",
    "de categor칤as ( positivo/negativo/neutro, enfermo/sano, \n",
    "aparece una persona/no aparece una persona). El caso particular en \n",
    "que solo existen dos categor칤as se denomina clasificaci칩n binaria.\n",
    "\n",
    "Dado que la clasificaci칩n es una t칠cnica supervisada es necesario \n",
    "contar con el conjunto de datos $X$ as칤 como con su conjunto de etiquetas \n",
    "$y$.  Donde  $X=\\{x_1,...,x_n\\}$  y cada elemento $x_i$ est치 definido en  $\\mathbb{R}^m$ y $y=\\{\\theta_1 ,...,\\theta_n\\}$ donde  $\\theta_i$ es la etiqueta correspondiente a cada $x_i$  y se define en $\\{1,...,k\\}$ para $k$  diferentes \n",
    "categor칤as."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Centroid Classifier\n",
    "\n",
    "Nearest Centroid (NC)  es un clasificador (tambi칠n llamado Mean Difference Classifier) simple y poderoso. NC  es un claro ejemplo del  principio de suficiencia estad칤stica, el cual nos dice que se pueden construir algoritmos a partir de res칰menes simples y significativos de los datos de entrenamiento. La forma m치s simple de resumir un conjunto de datos es mediate su media geom칠trica o centroide.  NC  como clasificador asigna a cada ejemplo desconocido la misma clase de su centroide m치s cercano.\n",
    "\n",
    "Nearest Centroid en combinaci칩n con representaciones vectoriales ha sido ampliamente utilizado para la clasificaci칩n de documentos, cada centroide es visto como una sumarizaci칩n de todos los documentos conocidos para una determinada clase. Dado el conjunto de vectores $X$ (generados mediante alguna t칠cnica de vectorizaci칩n) y etiquetas $y$ con valores  $C= \\{1,...,洧녲\\}$ para $k$ diferentes categorias (para el caso binario $C=\\{0,1\\}$). Para obterne un clasificador NC se deben generar un centroide por cada clase. \n",
    "\n",
    "Para continuar con la notaci칩n de clustering que utilizamos en la secci칩n anterior tenemos que:  $G_i$ es el conjunto de documentos que perteneces a la i칠sima clase y $c_i$ el centroide del grupo $G_i$. Como ya vimos cada $c_i$ puede no ser siempre la media geom칠trica (recuerde pod칤a ser la mediana o incluso un elemento del conjunto). En el caso de representaciones de texto existen muchas propuestas para el c치lculo del *\"centroide\"* reportadas en la literatura. Algunas de las m치s b치sicas son:\n",
    "\n",
    "\n",
    "- **Rocchio**, para este caso cada centroide $c_j$ es representado por la suma de todos los vectores de la clase $i$ menos la suma de aquellos vectores que no pertenecen a la clase $i$, se puede realizar un pesado mediante par치metros de control $\\beta$ y $\\gamma$ (usualmente $\\beta=16$ y $\\gamma=4$).\n",
    "\n",
    "$$c_j= \\beta \\frac{1}{|G_j|} \\sum_{x_i \\in G_j} x_i- \\gamma \\frac{1}{|X|-|G_j|} \\sum_{x_i \\notin G_j} x_i$$\n",
    "\n",
    "- El **promedio**, donde cada centroide es calculado c칩mo la media geom칠trica de cada grupo.\n",
    "\n",
    "$$c_j=\\frac{1}{|G_j|}\\sum_{x_i \\in G_j} x_i$$\n",
    "\n",
    "- La **suma**, es similar al promedio solo sin dividir por la cardinalidad del grupo\n",
    "\n",
    "$$c_j=\\sum_{x_i \\in G_j} x_i$$\n",
    "\n",
    "- La **suma normalizada**, cada centroide $c_j$ es calculado como la suma de todos los vectores de la clase $j$ pero normalizados. \n",
    "\n",
    "$$c_j= \\frac{1}{||\\sum_{x_i \\in G_j} x_i||}\\sum_{x_i \\in G_j} x_i$$\n",
    "\n",
    "Como ya podr치 haberse inferido las etapa de entrenamiento y el proceso de predicci칩n de un clasificador NC es muy eficiente, ya que para aprender solo se debe calcular el centroide para cada clase y para la predicci칩n s칩lo encontrar el centroide m치s similar para el ejemplo a predecir. Mientras que el entrenamiento es lineal(multiplicado por un factor del costo de la funci칩n de similitud), el proceso de predicci칩n es constante ya que solo depende del n칰mero de clases y no del tama침o del conjunto de entrenamiento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificador $k$ Nearest Neighbor\n",
    "\n",
    "El clasificador $k$ nearest neighbor ($k$NN), es un m칠todo no param칠trico que utiliza todos ejemplos en el conjunto de entrenamiento para predecir la clase de los ejemplos no etiquetados. Por lo que no hay fase de entrenamiento, la predicci칩n se realiza mediante el uso de una funci칩n de similitud/distancia.\n",
    "\n",
    "El clasificador $k$NN es simple e intuitivo, para $k=1$ funciona como sigue: dado un vector $x_q$, se le asocia la clase $\\theta_q$ que ser치 la misma que tenga el elemento m치s similar a $x_{nn} \\in X$ m치s similar a $x_q$. El objeto $x_{nn}$ se determina como  $\\arg\\!\\max_{1 \\leq i \\leq |X|} \\cos (x_q, x_i)$ cuando se utiliza la similitud coseno o bien como $\\arg\\!\\min_{1 \\leq i \\leq |X|} d(u, x_i)$  cuando se utiliza una funci칩n de distancia. Lo anterior da el origen al nombre desde que para determinar la clase de un objeto no etiquetado, primero debe encontrarse su vecino m치s cercano.  Una mejora directa es utilizar m치s de un vecino para calcular la clase de $x_q$, es decir utilizar $k>1$. Para $k>1$ se puede asignar a $x_q$ la clase que m치s se repita entre los $k$ vecinos m치s cercanos de $x_q$ (**pesado uniforme**)."
   ]
  },
  {
   "attachments": {
    "knn.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|![knn.png](attachment:knn.png)|\n",
    "|:--:|\n",
    "|**Consulta $k$NN para diferentes valores de $k$**|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pesado de vecinos por distancia\n",
    "\n",
    "Tambi칠n es com칰n realizar un pesado de la contribuci칩n de cada vecino basados en el valor de la funci칩n de distancia o similitud. Para nuestro caso solo utilizaremos dos variantes simples. \n",
    "\n",
    "-  **$k$NN distancia/similitud media**: En este caso se asigna a  $x_q$ la clase en la que la distancia media de los $k$ vecinos seleccionados sea menor. Mientras que se utiliza el valor mayor cuando se utiliza una funci칩n de similitud.\n",
    "- **$k$NN pesado por distancia**: Una forma b치sica de pesar cuando se utiliza una funci칩n de distancia es asignar a cada etiqueta un peso equivalente al inverso de la distancia. En el caso de la similitud puede ser el valor normalizado de la misma(cuando se usa coseno el valor ya est치 entre 0 y 1). Se asigna la clase que tenga el mayor peso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo suponga que la informaci칩n de cinco vecinos m치s cercanos para un $x_q$ dado en problema de 3 clases se resumen en la siguiente tabla. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|&nbsp;|$x_1$|$x_2$|$x_3$|$x_4$|$x_5$|\n",
    "|:------------:|:---:|:---:|:---:|:---:|:---:|\n",
    "|Clase de $x_i$|  2  |  1  |  2  |  1  |  0  |\n",
    "|$$d(x_i,x_q)$$| 0.5 | 0.2 |0.25 | 0.4 |0.125|\n",
    "|$$w_{x_i}$$       |  2  |  5  |  4  | 2.5 |  8  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "en las siguiente tabla se muestra como se calculan los scores para cada clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| <br /> | distancia media                    | pesado por distancia |uniforme|\n",
    "|:------:|:---------------------------------: |:--------------:       |:----:|\n",
    "|Clase 0 |  $d(x_5,x_q)/1$=**0.125**          |$w_{x_0}$=**8**            |   1  |\n",
    "|Clase 1 |  $$(d(x_2,x_q)+d(x_4,x_q))/2=0.3$$   |$$w_{x_2}+w_{x_4}=7.5$$|   **2**  |\n",
    "|Clase 2 |  $$(d(x_1,x_q)+d(x_3,x_q))/2=0.225$$ |$$w_{x_1}+w_{x_3}=6$$  |   **2**  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "usando la informaci칩n en la tabla anterior podemos ver que para $k=5$, si se utiliza el criterio de la distancia m칤nimo promedio la clase para $x_q$ ser칤a 0, al igual que para el pesado por distancia; mientras que para la decisi칩n por mayor칤a de votos podr칤a ser la clase 1 o 2. \n",
    "\n",
    "**Nota**: Si se utiliza una funci칩n de similitud no es necesario calcular el inverso, pero es buena idea normalizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple outputs per cell in Jupyter \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "// Evitar autoscroll.\n",
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "// Evitar autoscroll.\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from skeleton import *\n",
    "from sklearn.metrics import (recall_score, f1_score,\n",
    "                             precision_score, accuracy_score)\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testClassifier(clf,train,y_train,test,y_test):\n",
    "    print(\"=== \",clf.__class__.__name__,end='')\n",
    "    print(\":\",vars(clf))\n",
    "    clf=clf.fit(train,y_train)\n",
    "    #Predecimos las etiqueta del conjunto de prueba\n",
    "    yp=clf.predict(test)\n",
    "    # Medidas de bondad\n",
    "    scores={}\n",
    "\n",
    "    scores['Accuracy']=accuracy_score(y_test,yp)\n",
    "    scores['Macro F1']=f1_score(y_test,yp,average='macro')\n",
    "    scores['Macro Recall']=recall_score(y_test,yp,average='macro')\n",
    "    scores['F1 is_humor=1']=f1_score(y_test,yp)\n",
    "    \n",
    "    print(\"Accuracy\",\"Macro F1\",\"Macro Recall\",\"F1 is_humor=1\",sep='\\t')\n",
    "    print(\"{:.6f}\\t{:.6f}\\t{:.6f}\\t{:.6f}\".format(\n",
    "        scores['Accuracy'],scores['Macro F1'],scores['Macro Recall'],scores['F1 is_humor=1']))\n",
    "                            \n",
    "#     print(\"Recall: \", scores['recall'])\n",
    "#     print(\"F1: \", scores['f1'])\n",
    "#     print(\"Accuracy: \", scores['accuracy'])\n",
    "#     print(\"F1 Humor: \", scores['f1_humor'])\n",
    "    #Vemos la frontera de decisi칩n\n",
    "    plotDecisionBoundary(clf,train, y_train)\n",
    "    \n",
    "    del(clf)\n",
    "    del(yp)\n",
    "    gc.collect()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un problema de texto  (Identificaci칩n de humor HAHA -2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejemplo utilizaremos los datos proporcionados para la tarea 1 del HAHA - Humor Analysis based on Human Annotation, la cual consiste determinar si tweets en espa침ol son humor칤sticos o no (un problema de clasificaci칩n binaria). Esta tarea forma parte del Iberian Languages Evaluation Forum (IberLEF 2019)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus \n",
    "\n",
    "El conjunto de datos fue etiquetado como se indica [5]. Todos los tweets est치n etiquetados como humor칤stico **is_humor=1**  o no humor칤stico **is_humor=0**. Los datos relevantes para el problema se clasificaci칩n ser muestran en el siguiente ejemplo:\n",
    "\n",
    "|Desscripci칩n|Clave|Valor|\n",
    "|:------:|:------:|:-----:|\n",
    "|Tweet |text|Despu칠s de la tormenta sale... Tu mam치 gritando porque no metiste la ropa.|\n",
    "|Etiqueta de clase|is_humor|1|\n",
    "|Representaci칩n vectorial|vec| Vectores de dimensi칩n 300 (FastText preentrenados para espa침ol) |\n",
    "|Identificador|id|942079817905770496|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos lod datos.\n",
    "train_data=pd.read_json('data/haha_train_ft_pre.json',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos los primeros 5\n",
    "train_data.head()[['id','text','is_humor','vec']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimensi칩n de los vectores\n",
    "len(train_data.vec[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los datos de prueba\n",
    "test_data=pd.read_json('data/haha_test_ft_pre.json',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos la representaci칩n vectorial para los conjunto de prueba y entrenamiento\n",
    "train,y_train=np.array([np.array(x) for x in train_data.vec]),np.array(train_data.is_humor)\n",
    "test,y_test=np.array([np.array(x) for x in test_data.vec]),np.array(test_data.is_humor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "P={\"FastText\":{\"Accuracy\":0.809050,\"Macro F1\":0.793270,\"Macro Recall\":0.786900,\"F1 is_humor=1\":0.736140}} #Performance\n",
    "\n",
    "# # \n",
    "# P[\"NC.cos.avg\"]=testClassifier(NearestCentroid(distance='coseno',centroid_type='Average'),train,y_train,test,y_test)\n",
    "# P[\"NC.euc.avg\"]=testClassifier(NearestCentroid(distance='euclidiana',centroid_type='Average'),train,y_train,test,y_test)\n",
    "\n",
    "# P[\"NC.cos.sum\"]=testClassifier(NearestCentroid(distance='coseno',centroid_type='Sum'),train,y_train,test,y_test)\n",
    "# P[\"NC.euc.sum\"]=testClassifier(NearestCentroid(distance='euclidiana',centroid_type='Sum'),train,y_train,test,y_test)\n",
    "\n",
    "# P[\"NC.cos.rocchio\"]=testClassifier(NearestCentroid(distance='coseno',centroid_type='Rocchio',beta=16,gamma=4),train,y_train,test,y_test)\n",
    "# P[\"NC.euc.rocchio\"]=testClassifier(NearestCentroid(distance='euclidiana',centroid_type='Rocchio',beta=16,gamma=4),train,y_train,test,y_test)\n",
    "\n",
    "# P[\"NC.cos.nsum\"]=testClassifier(NearestCentroid(distance='coseno',centroid_type='NormSum'),train,y_train,test,y_test)\n",
    "# P[\"NC.euc.nsum\"]=testClassifier(NearestCentroid(distance='euclidiana',centroid_type='NormSum'),train,y_train,test,y_test)\n",
    "\n",
    "\n",
    "# P[\"KNN.cos.u\"]=testClassifier(kNN(distance='coseno',k=5,weight_type='uniform'),train,y_train,test,y_test)\n",
    "# P[\"KNN.euc.u\"]=testClassifier(kNN(distance='euclidiana',k=5,weight_type='uniform'),train,y_train,test,y_test)\n",
    "\n",
    "# P[\"KNN.cos.m\"]=testClassifier(kNN(distance='coseno',k=5,weight_type='mean_dist'),train,y_train,test,y_test)\n",
    "# P[\"KNN.euc.m\"]=testClassifier(kNN(distance='euclidiana',k=5,weight_type='mean_dist'),train,y_train,test,y_test)\n",
    "\n",
    "# P[\"KNN.cos.w\"]=testClassifier(kNN(distance='coseno',k=5,weight_type='weighed_dist'),train,y_train,test,y_test)\n",
    "# P[\"KNN.euc.w\"]=testClassifier(kNN(distance='euclidiana',k=5,weight_type='weighed_dist'),train,y_train,test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from toolbox import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    24000 data/haha_all_ft_pre.json\n",
      "      240 data/haha_all_ft_pre_min10.json\n",
      "     7201 data/haha_test_ft_pre.json\n",
      "       72 data/haha_test_ft_pre_min10.json\n",
      "    16799 data/haha_train_ft_pre.json\n",
      "      168 data/haha_train_ft_pre_min10.json\n",
      "    48480 total\n",
      "24000 data/haha_all_ft_pre.json\n",
      "** Processing data/haha_all_ft_pre.json ...\n",
      "2020-05-09 07:46:17.983991 :: 0.001201 - Processing item #0 \n",
      "2020-05-09 07:46:23.814103 :: 5.831313 - Processing item #5000 \n",
      "2020-05-09 07:46:27.711257 :: 9.728467 - Processing item #10000 \n",
      "2020-05-09 07:46:34.221749 :: 16.238959 - Processing item #15000 \n",
      "2020-05-09 07:46:38.431813 :: 20.449023 - Processing item #20000 \n",
      "** Processed 24000 lines. Saved to /home/jovyan/public/B5_Clasificacion/tokenized_docs.pickle.\n",
      "** Computing TF-IDF...\n",
      "** Computed TF-IDF Matrix !!!\n",
      "** Done poda0 TF-IDF Matrix !!!\n",
      "poda0_mtx.pickle written.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<15378x24000 sparse matrix of type '<class 'numpy.float16'>'\n",
       "\twith 165313 stored elements in List of Lists format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ab</th>\n",
       "      <th>aba</th>\n",
       "      <th>abac</th>\n",
       "      <th>abad</th>\n",
       "      <th>abaj</th>\n",
       "      <th>abajit</th>\n",
       "      <th>aban</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandonenl</th>\n",
       "      <th>abarzart</th>\n",
       "      <th>...</th>\n",
       "      <th>zucos</th>\n",
       "      <th>zuculini</th>\n",
       "      <th>zuli</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zum</th>\n",
       "      <th>zumb</th>\n",
       "      <th>zup</th>\n",
       "      <th>zuperm</th>\n",
       "      <th>zur</th>\n",
       "      <th>zuv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24000 rows 칑 15378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ab  aba  abac  abad  abaj  abajit  aban  abandon  abandonenl  \\\n",
       "0      0.0  0.0   0.0   0.0   0.0     0.0   0.0      0.0         0.0   \n",
       "1      0.0  0.0   0.0   0.0   0.0     0.0   0.0      0.0         0.0   \n",
       "2      0.0  0.0   0.0   0.0   0.0     0.0   0.0      0.0         0.0   \n",
       "3      0.0  0.0   0.0   0.0   0.0     0.0   0.0      0.0         0.0   \n",
       "4      0.0  0.0   0.0   0.0   0.0     0.0   0.0      0.0         0.0   \n",
       "...    ...  ...   ...   ...   ...     ...   ...      ...         ...   \n",
       "23995  0.0  0.0   0.0   0.0   0.0     0.0   0.0      0.0         0.0   \n",
       "23996  0.0  0.0   0.0   0.0   0.0     0.0   0.0      0.0         0.0   \n",
       "23997  0.0  0.0   0.0   0.0   0.0     0.0   0.0      0.0         0.0   \n",
       "23998  0.0  0.0   0.0   0.0   0.0     0.0   0.0      0.0         0.0   \n",
       "23999  0.0  0.0   0.0   0.0   0.0     0.0   0.0      0.0         0.0   \n",
       "\n",
       "       abarzart  ...  zucos  zuculini  zuli  zulu  zum  zumb  zup  zuperm  \\\n",
       "0           0.0  ...    0.0       0.0   0.0   0.0  0.0   0.0  0.0     0.0   \n",
       "1           0.0  ...    0.0       0.0   0.0   0.0  0.0   0.0  0.0     0.0   \n",
       "2           0.0  ...    0.0       0.0   0.0   0.0  0.0   0.0  0.0     0.0   \n",
       "3           0.0  ...    0.0       0.0   0.0   0.0  0.0   0.0  0.0     0.0   \n",
       "4           0.0  ...    0.0       0.0   0.0   0.0  0.0   0.0  0.0     0.0   \n",
       "...         ...  ...    ...       ...   ...   ...  ...   ...  ...     ...   \n",
       "23995       0.0  ...    0.0       0.0   0.0   0.0  0.0   0.0  0.0     0.0   \n",
       "23996       0.0  ...    0.0       0.0   0.0   0.0  0.0   0.0  0.0     0.0   \n",
       "23997       0.0  ...    0.0       0.0   0.0   0.0  0.0   0.0  0.0     0.0   \n",
       "23998       0.0  ...    0.0       0.0   0.0   0.0  0.0   0.0  0.0     0.0   \n",
       "23999       0.0  ...    0.0       0.0   0.0   0.0  0.0   0.0  0.0     0.0   \n",
       "\n",
       "       zur  zuv  \n",
       "0      0.0  0.0  \n",
       "1      0.0  0.0  \n",
       "2      0.0  0.0  \n",
       "3      0.0  0.0  \n",
       "4      0.0  0.0  \n",
       "...    ...  ...  \n",
       "23995  0.0  0.0  \n",
       "23996  0.0  0.0  \n",
       "23997  0.0  0.0  \n",
       "23998  0.0  0.0  \n",
       "23999  0.0  0.0  \n",
       "\n",
       "[24000 rows x 15378 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!rm -f *.pickle\n",
    "!wc -l data/haha_*.json\n",
    "# !cat data/haha_train_ft_pre_min10.json > data/haha_all_ft_pre_min10.json\n",
    "# !cat data/haha_test_ft_pre_min10.json >> data/haha_all_ft_pre_min10.json\n",
    "# !wc -l data/haha_all_ft_pre_min10.json\n",
    "!cat data/haha_train_ft_pre.json > data/haha_all_ft_pre.json\n",
    "!cat data/haha_test_ft_pre.json >> data/haha_all_ft_pre.json\n",
    "!wc -l data/haha_all_ft_pre.json\n",
    "\n",
    "!rm -f *.pickle\n",
    "inv_idx = InvertedIdx(\"data/haha_all_ft_pre.json\")\n",
    "inv_idx.process(showProgressEach=5000)\n",
    "inv_idx.compute_mtx()\n",
    "tfidf=pd.DataFrame(inv_idx.idx_mtx.todense(), index=inv_idx.corpus).T\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n=len(train_data)\n",
    "test_n=len(test_data)\n",
    "train_n,test_n # (16799, 7201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(inv_idx)\n",
    "# del(train_data)\n",
    "# del(test_data)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2=np.array([np.array(row,dtype='float16') for _, row in tfidf.tail(7201).iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2=np.array([np.array(row,dtype='float16') for _, row in tfidf.head(16799).iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(tfidf)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos lod datos.\n",
    "train_data=pd.read_json('data/haha_train_ft_pre.json',lines=True)\n",
    "#Obtenemos la representaci칩n vectorial para los conjunto de prueba y entrenamiento\n",
    "y_train=np.array(train_data.is_humor,dtype='int')\n",
    "# Los datos de prueba\n",
    "test_data=pd.read_json('data/haha_test_ft_pre.json',lines=True)\n",
    "y_test=np.array(test_data.is_humor)\n",
    "\n",
    "del(train_data)\n",
    "del(test_data)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train2=np.array(tfidf.head(train_n))\n",
    "# test2=np.array(tfidf.tail(test_n))\n",
    "# train2.shape,test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train2=np.ascontiguousarray(tfidf.head(train_n).to_numpy())\n",
    "# test2=np.ascontiguousarray(tfidf.tail(test_n).to_numpy())\n",
    "# train2.shape,test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "P2={} #Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "P2[\"NC.cos.avg\"]=testClassifier(NearestCentroid(distance='coseno',centroid_type='Average'),train2,y_train,test2,y_test)\n",
    "P2[\"NC.euc.avg\"]=testClassifier(NearestCentroid(distance='euclidiana',centroid_type='Average'),train2,y_train,test2,y_test)\n",
    "\n",
    "P2[\"NC.cos.sum\"]=testClassifier(NearestCentroid(distance='coseno',centroid_type='Sum'),train2,y_train,test2,y_test)\n",
    "P2[\"NC.euc.sum\"]=testClassifier(NearestCentroid(distance='euclidiana',centroid_type='Sum'),train2,y_train,test2,y_test)\n",
    "\n",
    "P2[\"NC.cos.rocchio\"]=testClassifier(NearestCentroid(distance='coseno',centroid_type='Rocchio',beta=16,gamma=4),train2,y_train,test2,y_test)\n",
    "P2[\"NC.euc.rocchio\"]=testClassifier(NearestCentroid(distance='euclidiana',centroid_type='Rocchio',beta=16,gamma=4),train2,y_train,test2,y_test)\n",
    "\n",
    "P2[\"NC.cos.nsum\"]=testClassifier(NearestCentroid(distance='coseno',centroid_type='NormSum'),train2,y_train,test2,y_test)\n",
    "P2[\"NC.euc.nsum\"]=testClassifier(NearestCentroid(distance='euclidiana',centroid_type='NormSum'),train2,y_train,test2,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "P2[\"KNN.cos.u\"]=testClassifier(kNN(distance='coseno',k=5,weight_type='uniform'),train2,y_train,test2,y_test)\n",
    "P2[\"KNN.euc.u\"]=testClassifier(kNN(distance='euclidiana',k=5,weight_type='uniform'),train2,y_train,test2,y_test)\n",
    "\n",
    "P2[\"KNN.cos.m\"]=testClassifier(kNN(distance='coseno',k=5,weight_type='mean_dist'),train2,y_train,test2,y_test)\n",
    "P2[\"KNN.euc.m\"]=testClassifier(kNN(distance='euclidiana',k=5,weight_type='mean_dist'),train2,y_train,test2,y_test)\n",
    "\n",
    "P2[\"KNN.cos.w\"]=testClassifier(kNN(distance='coseno',k=5,weight_type='weighed_dist'),train2,y_train,test2,y_test)\n",
    "P2[\"KNN.euc.w\"]=testClassifier(kNN(distance='euclidiana',k=5,weight_type='weighed_dist'),train2,y_train,test2,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(P).T.sort_values(\"F1 is_humor=1\",ascending =False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame(P2).T.sort_values(\"F1 is_humor=1\",ascending =False)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
